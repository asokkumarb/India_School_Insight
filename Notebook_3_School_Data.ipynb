{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Notebook_3_School_Data.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chquoqXBN9d3",
        "colab_type": "text"
      },
      "source": [
        "###Schools Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MK1nFXXP9WXK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import the necessary packages\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "from IPython.core.display import clear_output\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from time import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cm1_SswctckG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#read the school links\n",
        "school_link = pd.read_csv('/content/drive/My Drive/data_s/all_school_links')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jaxF2HabCMJg",
        "colab_type": "text"
      },
      "source": [
        "As the Data we are trying to scrape is around 2.5 lakhs we will do this in batches of 20k."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18EW1DP-uE1u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s_links = school_link['links'][ :20000 ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gd1nXPf8miKq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "full = [] #create a empty list\n",
        "start_time = time () #start time\n",
        "no_request = 0 #intialize request to 0\n",
        "\n",
        "for s in s_links: #iterate over all the school all the links\n",
        "  download_html = requests.get(s) #make request to server\n",
        "  soup = BeautifulSoup(download_html.text) #create BeautfifulSoup object parse-html\n",
        "  full_ul = soup.select('ul.list-group')   #select all the ul.list-group\n",
        "  \n",
        "  rows = []  #create empty list rows\n",
        "\n",
        "  no_request+=1  #update reuquests by 1 after each iteration\n",
        "  elapsed_time = time() - start_time  #count elapsed time\n",
        "  print('Request:{}; Frequency: {} requests/s'.format(no_request, no_request/elapsed_time)) #check request frequency\n",
        "  clear_output(wait = True)  #clear output after each iteration\n",
        "\n",
        "  for tag in full_ul: #iterate over all ul list\n",
        "    b_elements = tag.select('li b')  #select <b> tag \n",
        "\n",
        "    for j in b_elements: #iterate over <b> tags\n",
        "      b = j.text   #get text\n",
        "      rows.append(b)  #append row with data scrape from <b> tag\n",
        "\n",
        "  full.append(rows)  #append the full with rows we will get list of lists\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3grdyc5OvJwB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(full)  #check length"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3ZD2Wv4rt24",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#these are the columns of our Dataframe\n",
        "columns = ['Instruction_Medium', 'Male_Teachers', 'Pre_Primary_Sectin_Avilable',\n",
        "       'Board_for_Class_10th', 'School_Type', 'Classes',\n",
        "       'Female_Teacher', 'Pre_Primary_Teachers', 'Board_for_Class_10+2',\n",
        "       'Meal_Not_Applicable', 'Establishment', 'School_Area',\n",
        "       'School_Shifted_to_New_Place', 'Head_Teachers', 'Head_Teacher',\n",
        "       'Is_School_Residential', 'Residential_Type', 'Total_Teachers',\n",
        "       'Contract_Teachers', 'Management', 'Village_/_Town', 'Cluster', 'Block',\n",
        "       'District', 'State', 'UDISE_Code', 'Building', 'Class_Rooms',\n",
        "       'Boys_Toilet', 'Girls_Toilet', 'Computer_Aided_Learning', 'Electricity',\n",
        "       'Wall', 'Library', 'Playground', 'Books_in_Library', 'Drinking_Water',\n",
        "       'Ramps_for_Disable', 'Computers']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8zs5q9xbISI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#store the Data in DataFrame\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "df = pd.DataFrame (full,columns = columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeRWQ55FMwDL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#save the data to drive\n",
        "df.to_csv('data_s_20000.csv')\n",
        "!cp data_s_20000.csv '/content/drive/My Drive/data_s'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ee9P68cmsQ9R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}